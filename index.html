	<!DOCTYPE html>
	<html>
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="description" content="I'm a postdoc in the department of Brain and Cognitive Sciences at MIT, in Ruth Rosenholtz' lab, studying peripheral vision, visual attention and eye movements, and using driving to understand how we acquire the visual information we need to move through the world. I received my PhD in 2015 from UC Berkeley, where I was advised by David Whitney.">
		<title>Ben Wolfe | MIT</title>
	<!--
	Neaty HTML Template
	http://www.templatemo.com/tm-501-neaty
	-->
		<!-- load stylesheets -->
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,400">  <!-- Google web font "Open Sans" -->
		<link rel="stylesheet" href="css/bootstrap.min.css">                                      <!-- Bootstrap style -->
		<link rel="stylesheet" href="css/magnific-popup.css">                                <!-- Magnific pop up style, http://dimsemenov.com/plugins/magnific-popup/ -->
		<link rel="stylesheet" href="css/templatemo-style.css">                                   <!-- Templatemo style -->

		<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
		<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
			<!--[if lt IE 9]>
			  <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
			  <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
			  <![endif]-->
			<script src="js/jquery-1.11.3.min.js"></script>             <!-- jQuery (https://jquery.com/download/) -->
			<script src="js/jquery.magnific-popup.min.js"></script>     <!-- Magnific pop-up (http://dimsemenov.com/plugins/magnific-popup/) -->
			<script src="js/jquery.singlePageNav.min.js"></script>      <!-- Single Page Nav (https://github.com/ChrisWojcik/single-page-nav) -->
		<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123761048-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-123761048-1');
	</script>
	</head>
		<body>        
			<div class="container">
				<div class="row">
					<div class="tm-left-right-container">
						<!-- Left column: logo and menu -->
						<div class="tm-blue-bg tm-left-column">                        
							<div class="tm-logo-div text-xs-center">
							  <h1 class="tm-site-name">Ben Wolfe</h1>
							</div>
							<nav class="tm-main-nav">
								<ul class="tm-main-nav-ul">
									<li class="tm-nav-item">
										<a href="#about" class="tm-nav-item-link">About me</a>
									</li>
									<li class="tm-nav-item">
										<a href="#research" class="tm-nav-item-link">Research</a>
									</li>
									<li class="tm-nav-item">
										<a href="#publications" class="tm-nav-item-link">Publications</a>
									</li>
								   <li class="tm-nav-item">
										<a href="#press" class="tm-nav-item-link">Press</a>
									</li> 
									<li class="tm-nav-item">
										<a href="#contact" class="tm-nav-item-link">Contact</a>
									</li>
								</ul>
							</nav>                                         
						</div> <!-- Left column: logo and menu -->

						<!-- Right column: content -->
						<div class="tm-right-column" style="padding-bottom:0px">
						   <!--  <figure>
							<img src="img/patterncopy3-01.png" alt="Header image" class="img-fluid">
							</figure>-->

							<div class="tm-content-div" >

							  <!-- About section -->
								<section id="about" class="tm-section">

								  <div class="row">                                                                
									<div class="col-lg-8 col-md-7 col-sm-12 col-xs-12 push-lg-4 push-md-5">
									  <header><h2 class="tm-blue-text tm-section-title tm-margin-b-30" align="left
								">About me</h2></header>

										In January 2021, I'll be starting as an Assistant Professor in the <a href="https://www.utm.utoronto.ca/psychology/">Psychology Department</a> at the <a href="https://www.utm.utoronto.ca/">University of Toronto, Mississauga</a> where I'll be running the <a href="https://www.applylab.org">Applied Perception and Psychophysics Laboratory</a> with <a href="https://www.annakosov.net">Dr Anna Kosovicheva</a>. 

										<br><br>
										My research interests are broadly use-inspired: recently, I've been interested in what information drivers need to be safe on the road (and what information self-driving cars need to know about their drivers), how we can make text on screens (like this webpage, or a PDF) more readable, how we plan eye movements in dynamic natural scenes and how we use peripheral vision.

										<br> <br>
										Are you interested in applied or translational questions in vision science and thinking about graduate school? Please get in <a href="benjamin.wolfe@utoronto.ca">touch</a> - I'm recruiting graduate students to start in Fall, 2021. <br>
										<br>
	Until the end of 2020, I'm a senior postdoctoral associate at <a href="http://web.mit.edu/">MIT</a> in the <a href="http://bcs.mit.edu">Department of Brain and Cognitive Sciences</a> in <a href="http://persci.mit.edu/people/rosenholtz">Ruth Rosenholtz's</a> lab. I'm also affiliated with MIT's <a href="http://csail.mit.edu">Computer Science and Artificial Intelligence Lab</a>.  I received my Ph.D. in Psychology in 2015 from UC Berkeley, and was advised by <a href="https://whitneylab.berkeley.edu/">David Whitney</a>.<br>
	<br>


	<br>
	<p><a href="pdf/Wolfe_CurriculumVitae.pdf">Download CV (pdf)</a><br>
	  <a href="https://scholar.google.com/citations?user=1YBcrmYAAAAJ&amp;hl=en">Google Scholar profile</a></p>
	<!--  <a href="#" class="tm-button tm-button-wide">Read More</a>   -->

									  </div>

										<div class="col-lg-4 col-md-5 col-sm-12 col-xs-12 pull-lg-8 pull-md-7 tm-about-img-container" align="center">
											<img src="img/bwolfe_headshot.jpg" alt="Ben Wolfe Photo" width="300" class="img-fluid">    
									  </div>  
								  </div>                            
								</section>  

								<!-- Research section -->                 
							  <section id="research" class="tm-section">

											<h2 class="tm-blue-text tm-section-title tm-margin-b-30" align="left" style="margin-bottom:30px">Research</h2>

						<div class="row subsection"> 


						  <div class="col-lg-8" style="vertical-align: middle"> 
							<h4>How can driving teach us about vision?</h4>
	Driving is inherently visual, but what do drivers need to know about the road to stay safe and keep everyone around them safe? 
						  Are they aware of <a href="#ufov">changes across the visual field</a>, or just from a tunnel around where they're looking? What happens when they're distracted by their <a href="#distraction">smartphone</a>? How quickly can they understand what has <a href="#hazards">changed in the scene</a> (and notice the moose that just walked into the road)? How well do they represent the <a href="#prediction">richness of their environment</a>, and how do they <a href="#information_acquisition">acquire the information</a> they need before the world (or the moose) catches up to them? </div>  
						  <div class="col-lg-4" style="vertical-align: middle" align="center"><figure><img src="img/driving.png" width="300" alt="Countryside" class="img-fluid img-fluid2" style="margin-top:0px"/></figure></div>
								</div>
								  
								<div class="row subsection">
										   <div class="col-lg-4" style="vertical-align: middle" align="center"><figure><img src="img/eyetracking.png" width="300" alt="Intersection with shop" class="img-fluid img-fluid2"></figure></div>
								  <div class="col-lg-8" style="margin-top:23px">
								    <h4>Eye Movements and Perception</h4>
	We make saccades (directed eye movements) several times a second; why? Sometimes, it's to overcome the limits of peripheral vision (e.g., when objects in the periphery are <a href="#crowded-faces">crowded</a> and unidentifiable). But we don't notice these shifts of viewpoint much; how do we stitch our percpetual world together into something stable? We use information from peripheral vision <a href="#remapping">acquired before we move our eyes</a> and use it to achieve stability. How, then, do we use <a href="#information-acquisition">eye movements in real-world settings</a>, when we're moving through the world?
									  
									  

												</div> 
							   </div>
	<div class="row">
					   <div class="col-lg-8" style="margin-top:15px"> 
										 <h4>Visual Perception and Aging</h4>
	
						   Our visual systems change as we age (it's inevitable), so how does that impact how we perceive the visual world? Older readers have a harder time with <a href="#age-text">distorted or degraded text</a>, and with some <a href="#signs-of-the-times">fonts on road signs</a>. Older drivers also have a <a href="#hazards">harder time noticing dangerous changes</a> (like a moose running into the road), which makes understanding perception across the lifespan critical for translating vision science out of the lab and into the world.
						   
					

						   </div><div class="col-lg-4" style="vertical-align: middle" align="center"><figure><img src="img/scene.png" width="300" alt="Eye closeup" class="img-fluid img-fluid2" style="margin-top:4px"/></figure></div>
								</div>
								<div class="row subsection">
								  <div class="col-lg-4" style="vertical-align: middle" align="center">
									<figure><img src="img/peripheral_vision.jpg" width="300" alt="Eye closeup" class="img-fluid img-fluid2"></figure>
								  </div>
								  <div class="col-lg-8" style="margin-top:23px">
									<h4>Peripheral Vision</h4>
	It's easy to focus on just where we're looking in a scene or a laboratory experiment, but that's only a tiny fraction of the retina. Peripheral vision, the rest of our visual field, is immensely important if we are to understand how we use vision in the world. We use it to <a href="#ensemble-fovea">understand groups</a> (like a classroom of students) faster than we can look at each individual. We use it to <a href="#distraction">monitor the road</a>, even when we're focused on something else. It's essential <a href="#remapping">to plan eye movements</a> and to alleviate <a href="#crowded-faces">crowding</a>. It's seldom considered in <a href="#ufov">driving</a>, but is probably key to how <a href="#information-acquisition">drivers acquire the information they need</a>.
									  
									  </div>
								</div>                       
							  </section>  

								<!-- Publications -->     
								<section id="publications" class="tm-section">
									<header><h2 class="tm-blue-text tm-section-title tm-margin-b-30">Publications</h2></header>

									<div class="row tm-pub" id="information_acquisition" ><strong>Towards a theory of visual information aquisition in driving</strong><br>
	 Wolfe, B., Sawyer, B.D., Rosenholtz, R. <br>
	<em>Human Factors </em> (2020)&nbsp; • <a href="pdf/Wolfe_HF_2020.pdf">pdf</a>  <br>
	</div>


									<div class="row tm-pub" id="backgrounds" ><strong>Glanceable, legible typography over complex backgrounds</strong><br>
	Sawyer, B.D., Wolfe, B.,  Dobres, J.,  Chahine, N., Reimer, B. <br>
	<em>Ergonomics</em> (2020)&nbsp; • <a href="pdf/Sawyer_Ergo_2020.pdf">pdf</a> <br>
	</div>

									<div class="row tm-pub" id="hazards"><strong>Rapid Holistic Perception and Evasion of Road Hazards</strong><br>
	Wolfe, B., Seppelt, B.D., Mehler, B.,  Reimer, B., Rosenholtz, R. <br>
	<em>Journal of Experimental Psychology: General</em> (2019)&nbsp; • <a href="pdf/Wolfe_JEPg_2019.pdf">pdf</a> <br> 

								  <strong>Road Hazard Stimuli</strong> (described in the JEP:General paper) • <a href="https://osf.io/uq6pc/">Available on OSF</a> </div>

									<div class="row tm-pub" id="distraction"><strong>Detection of Brake Lights While Distracted: Separating Peripheral Vision from Cognitive
	Load</strong><br>
	Wolfe, B., Sawyer, B.D., Kosovicheva, A.,  Reimer, B., Rosenholtz, R. <br>
	<em>Attention, Perception and Psychophysics</em> (2019)&nbsp; • <a href="pdf/Wolfe_APP_2019.pdf">pdf</a> <br>
	</div>
									<div class="row tm-pub" id="prediction"><strong>Predicting road scenes from brief views of driving video.</strong><br>
	Wolfe, B., Fridman, L., Kosovicheva, A., Seppelt, B., Mehler, B., Reimer, B., Rosenholtz, R. <br>
	<em>Journal of Vision</em> (2019)&nbsp; • <a href="pdf/Wolfe_JoV_2019.pdf">pdf</a><br>
	</div>
	<div class="row tm-pub" id="unifying-space2"><strong>The effects of visual crowding, text size, and positional uncertainty on text legibility at a glance.</strong><br>
	Dobres, J., Wolfe, B. A., Chahine, N., Reimer, B. <br>
	<em>Applied Ergonomics</em> (2018)&nbsp; • <a href="pdf/Dobres_AppErgo_2018.pdf">pdf</a><br>
	</div>
	<div class="row tm-pub" id="unifying-space"><strong>Unifying visual space across the right and left hemifields.</strong><br>
	  Chen, Z.*, Kosovicheva, A.*, Wolfe, B. A., Cavanagh, P., Gorea, A., &amp; Whitney, D. <br>
	  <em>Psychological Science</em> (2018)&nbsp; • <a href="pdf/Chen_PsychSci_2018.pdf">pdf</a><br>
	</div>
						   <div class="row tm-pub" id="ufov"><strong>More Than the Useful Field: Considering Peripheral Vision in Driving.</strong><br>
	Wolfe, B.A., Dobres, J., Rosenholtz, R., &amp; Reimer, B.. <br>
	<em>Applied Ergonomics </em> (2017) &#8226; <a href="pdf/Wolfe_UFOV_2017.pdf">pdf</a></div>
						   <div class="row tm-pub" id="road-predict"><strong>Perceiving The Roadway In The Blink Of An Eye – Rapid Perception Of The Road Environment And Prediction Of Events.</strong><br>Wolfe, B., Fridman, L., Kosovicheva, A., Seppelt, B., Mehler, B., Reimer, B. <br>
							 <em>Driving Assessment </em>(2017) &#8226; <a href="pdf/Wolfe_Driving_Assessment_2017.pdf">pdf</a></div>
						   <div class="row tm-pub" id="signs-of-the-times"><strong>Signs of the Times: An Empirical Assessment of the Legibility of Highway Gothic and Clearview Signage Fonts.</strong> <br>  Dobres, J., Chrysler, S. T., Wolfe, B., Chahine, N., &amp; Reimer, B. <br>
							 <em>Transportation Research Board </em>(2017) &#8226; <a href="pdf/Dobres_TRB_2017.pdf">pdf</a></div>
						   <div class="row tm-pub" id="age-text"><strong>Age-related differences in the legibility of degraded text.</strong><br>
	Wolfe, B., Dobres, J., Kosovicheva, A., Rosenholtz, R., &amp; Reimer, B.<br>
	<em>Cognitive Research: Principles and Implications</em> (2016) &#8226; <a href="pdf/Wolfe_CRPI_2016.pdf">pdf </a></div>
						   <div class="row tm-pub" id="ensemble-fovea"><strong>Foveal input is not required for ensemble perception of emotional faces.</strong> <br>
	Wolfe, B. A., Kosovicheva, A. A., Yamanashi Leib, A., Wood, K. &amp; Whitney, D.<br>
	<em>Journal of Vision</em> (2015) &#8226; <a href="pdf/Wolfe_JOV_2015.pdf">pdf</a></div>
						   <div class="row tm-pub" id="remapping"><strong>Saccadic remapping of object-selective information.</strong> <br>
	Wolfe, B. A., Whitney, D.<br>
	<em>Attention, Perception and Psychophysics </em>(2015) &#8226; <a href="pdf/Wolfe_APP_2015.pdf">pdf</a></div>
						   <div class="row tm-pub" id="crowded-faces"><strong>Facilitating recognition of crowded faces with presaccadic attention.</strong> <br>
	Wolfe, B. A., Whitney, D.<br>
	<em>Frontiers in Human Neuroscience </em>(2014) &#8226; <a href="pdf/Wolfe_FiHN_2014.pdf">pdf</a></div>
						   <div class="row tm-pub" id="motion-saccade"><strong>Visual motion shifts saccade targets.</strong><br>
	Kosovicheva, A. A., Wolfe, B. A., &amp; Whitney, D.<br>
	<em>Attention, Perception, &amp; Psychophysics</em> (2014) &#8226; <a href="pdf/Kosovicheva_APP_2014.pdf">pdf</a></div>
						   <div class="row tm-pub" id="attention-test"><strong>Coping With Spatial Attention in Real Space: A Low-Cost Portable Testing System for the Investigation of Visuo-Spatial Processing in the Human Brain.</strong><br>
	Wolfe, B.A., Rushmore, R.J., Valero-Cabre, A..<br>
	<em>Journal of Neuroscience Methods</em> (2010) &nbsp;• <a href="pdf/Wolfe_JNM_2010.pdf">pdf</a></div>
						   <div class="row tm-pub" id="fmri"><strong>Multiscale pattern analysis of orientation-selective activity in the primary visual cortex.</strong><br>
	Swisher, J.D., Gatenby, J.C., Gore, J.C., Wolfe, B.A., Moon, C.H., Kim, S.G. Tong., F..<br>
	<em>Journal of Neuroscience</em> (2010)&nbsp; • <a href="pdf/Swisher_JNeuro_2010.pdf">pdf</a></div>
	<div class="row tm-pub"><em><strong>Note: </strong>The pdf reprints are protected by copyright laws, and are available only for personal, research use. Any other use is prohibited. </em></div>
								</section>

								<!-- Third Gallery section -->     
								<section id="press" class="tm-section">
									<h2 class="tm-blue-text tm-section-title tm-margin-b-30" style="margin-bottom:10px">Press</h2>

								   <div class="row tm-pub">
						<div class="col-sm-2" style="vertical-align: middle" align="center"><a href="https://www.csail.mit.edu/news/what-distracted-driving-narrative-gets-wrong"><figure><img src="img/driving.png" width="100" alt="Driving video still" class="img-fluid img-fluid2"></figure></a></div>

									  <p style="line-height: 1.7"><a href="https://www.csail.mit.edu/news/what-distracted-driving-narrative-gets-wrong">"What the distracted-driving narrative gets wrong."</a> <br>MIT CSAIL (June 24, 2019). <p style="line-height: 1.7"><a href="https://www.csail.mit.edu/news/what-distracted-driving-narrative-gets-wrong">"Your eyes are the key to distracted driving, not your brain"</a>  <br>Ars Technica (July 1, 2019). <br> <br> Referencing <strong><a href="pdf/Wolfe_APP_2019.pdf">Detection of brake lights while distracted: Separating peripheral vision from cognitive load</a> <br></strong> (Wolfe, Sawyer, Kosovicheva, & Reimer and Rosenholtz, 2019). </p></div>
									<div class="row tm-pub">

										<div class="row tm-pub">
						<div class="col-sm-2" style="vertical-align: middle" align="center"><a href="https://www.csail.mit.edu/news/what-distracted-driving-narrative-gets-wrong">
						<figure><img src="img/deer.png" width="274" alt="Driving video still" class="img-fluid img-fluid2"></figure></a></div>

									  <p style="line-height: 1.7"><a href="http://news.mit.edu/2019/how-fast-humans-react-car-hazards-0807">"Reacting to road hazards."</a> <br>MIT News (August 7, 2019).  <br> <br> Referencing <strong><a href="pdf/Wolfe_JEPg_2019.pdf">Holistic detection and evasion of road hazards</a> <br></strong> (Wolfe, Seppelt, Mehler, Reimer and Rosenholtz, 2019). </p></div>
									<div class="row tm-pub">

								</section>

								<!-- Contact Us section -->
								<section id="contact" class="tm-section">
									<header>
									  <h2 class="tm-blue-text tm-section-title tm-margin-b-30">Contact</h2>
									</header>
									<div class="row">
										<div class="col-lg-6">
											  <form id="contact-form" method="post" action="https://formspree.io/contact@benwolfe.net" role="form">
												<div class="form-group">
													<input type="text" id="name" name="name" class="form-control" placeholder="Name"  required/>
												</div>
												<div class="form-group">
													<input type="email" id="email" name="email" class="form-control" placeholder="Email"  required/>
												</div>
												<div class="form-group">
													<textarea id="message" name="message" class="form-control" rows="9" placeholder="Message" required></textarea>
												</div> 
												  <div class="form-group">
												<button type="submit" class="float-right tm-button">Send</button> </div>
												</form> 

												</div></div>

								</section>
								<footer>

								  <div class="tm-copyright-p">Designed by <a href="http://www.templatemo.com" target="_parent">templatemo</a>.</div>


								</footer>

							</div>    
							<!--<img src="img/patterncopy3-01.png" alt="Footer image" class="img-fluid" style="margin-bottom: 0px"> -->
						</div> <!-- Right column: content -->

				</div> <!-- row -->
			</div> <!-- container -->

			 </div>       
			<!-- load JS files -->

		  <script>     

				$(document).ready(function(){

					// Single page nav
					$('.tm-main-nav').singlePageNav({
						'currentClass' : "active",
						offset : 20
					});

					// Magnific pop up
					$('.tm-gallery-1').magnificPopup({
					  delegate: 'a', // child items selector, by clicking on it popup will open
					  type: 'image',
					  gallery: {enabled:true}
					  // other options
					}); 

					$('.tm-gallery-2').magnificPopup({
					  delegate: 'a', // child items selector, by clicking on it popup will open
					  type: 'image',
					  gallery: {enabled:true}
					  // other options
					}); 

					$('.tm-gallery-3').magnificPopup({
					  delegate: 'a', // child items selector, by clicking on it popup will open
					  type: 'image',
					  gallery: {enabled:true}
					  // other options
					}); 

					$('.tm-current-year').text(new Date().getFullYear());                
				});
	//        </script> 

	</body>
	</html>